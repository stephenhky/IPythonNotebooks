{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# link1: https://www.tensorflow.org/tutorials/seq2seq\n",
    "# link2: https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "class SentenceToCharVecEncoder:\n",
    "    def __init__(self, dictionary):\n",
    "        self.dictionary = dictionary\n",
    "        numchars = len(self.dictionary)\n",
    "        self.onehot_encoder = OneHotEncoder()\n",
    "        self.onehot_encoder.fit(np.arange(numchars).reshape((numchars, 1)))\n",
    "        \n",
    "    def encode_sentence(self, sent):\n",
    "        return self.onehot_encoder.transform(\n",
    "            np.array([self.dictionary.token2id[c] for c in sent]).reshape((len(sent), 1))\n",
    "        )\n",
    "    \n",
    "    def encode_sentences(self, sentences, sparse=True):\n",
    "        if sparse:\n",
    "            return map(lambda sent: self.encode_sentence(sent), sentences)\n",
    "        else:\n",
    "            return map(lambda sent: self.encode_sentence(sent).toarray(), sentences)\n",
    "    \n",
    "def initSentenceToCharVecEncoder(textfile):\n",
    "    text = filter(lambda t: len(t)>0, [t.strip()+'\\n' for t in textfile])\n",
    "    dictionary = Dictionary(map(lambda line: [c for c in line], text))\n",
    "    return SentenceToCharVecEncoder(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textfile = urllib2.urlopen('http://norvig.com/big.txt', 'r')\n",
    "text = filter(lambda t: len(t)>0, [t.strip() for t in textfile])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chartovec_encoder = initSentenceToCharVecEncoder(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n",
      "113\n"
     ]
    }
   ],
   "source": [
    "numchars = len(chartovec_encoder.dictionary)\n",
    "latent_dim = numchars + 20\n",
    "\n",
    "print numchars\n",
    "print latent_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2541\n"
     ]
    }
   ],
   "source": [
    "max_sentlen = max(map(lambda t: t.shape[0], chartovec_encoder.encode_sentences(text)))\n",
    "print max_sentlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "\n",
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, numchars))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, numchars))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the \n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(numchars, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preparing training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder_input = chartovec_encoder.encode_sentences(text[:-1])\n",
    "decoder_input = chartovec_encoder.encode_sentences(text[1:])\n",
    "decoder_output = chartovec_encoder.encode_sentences(text[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103500\n",
      "[(64, 93), (25, 93), (45, 93), (68, 93), (68, 93), (42, 93), (68, 93), (68, 93), (34, 93), (68, 93), (68, 93), (68, 93), (68, 93), (55, 93), (63, 93), (63, 93), (64, 93), (40, 93), (30, 93), (40, 93), (42, 93), (11, 93), (17, 93), (29, 93), (79, 93), (37, 93), (17, 93), (15, 93), (2, 93), (22, 93), (8, 93), (23, 93), (25, 93), (23, 93), (31, 93), (23, 93), (32, 93), (40, 93), (40, 93), (41, 93), (38, 93), (38, 93), (40, 93), (35, 93), (2, 93), (1146, 93), (1300, 93), (978, 93), (337, 93), (114, 93), (20, 93), (175, 93), (24, 93), (150, 93), (394, 93), (67, 93), (820, 93), (383, 93), (241, 93), (13, 93), (12, 93), (31, 93), (26, 93), (25, 93), (489, 93), (62, 93), (492, 93), (76, 93), (217, 93), (74, 93), (208, 93), (109, 93), (124, 93), (41, 93), (59, 93), (649, 93), (40, 93), (491, 93), (146, 93), (228, 93), (39, 93), (138, 93), (19, 93), (137, 93), (161, 93), (23, 93), (1126, 93), (193, 93), (170, 93), (270, 93), (183, 93), (298, 93), (25, 93), (8, 93), (232, 93), (39, 93), (293, 93), (104, 93), (273, 93), (108, 93)]\n"
     ]
    }
   ],
   "source": [
    "print(len(encoder_input))\n",
    "print(map(lambda e: e.shape, encoder_input[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103500\n",
      "[(25, 93), (45, 93), (68, 93), (68, 93), (42, 93), (68, 93), (68, 93), (34, 93), (68, 93), (68, 93), (68, 93), (68, 93), (55, 93), (63, 93), (63, 93), (64, 93), (40, 93), (30, 93), (40, 93), (42, 93), (11, 93), (17, 93), (29, 93), (79, 93), (37, 93), (17, 93), (15, 93), (2, 93), (22, 93), (8, 93), (23, 93), (25, 93), (23, 93), (31, 93), (23, 93), (32, 93), (40, 93), (40, 93), (41, 93), (38, 93), (38, 93), (40, 93), (35, 93), (2, 93), (1146, 93), (1300, 93), (978, 93), (337, 93), (114, 93), (20, 93), (175, 93), (24, 93), (150, 93), (394, 93), (67, 93), (820, 93), (383, 93), (241, 93), (13, 93), (12, 93), (31, 93), (26, 93), (25, 93), (489, 93), (62, 93), (492, 93), (76, 93), (217, 93), (74, 93), (208, 93), (109, 93), (124, 93), (41, 93), (59, 93), (649, 93), (40, 93), (491, 93), (146, 93), (228, 93), (39, 93), (138, 93), (19, 93), (137, 93), (161, 93), (23, 93), (1126, 93), (193, 93), (170, 93), (270, 93), (183, 93), (298, 93), (25, 93), (8, 93), (232, 93), (39, 93), (293, 93), (104, 93), (273, 93), (108, 93), (268, 93)]\n"
     ]
    }
   ],
   "source": [
    "print(len(decoder_input))\n",
    "print(map(lambda e: e.shape, decoder_input[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103500\n",
      "[(25, 93), (45, 93), (68, 93), (68, 93), (42, 93), (68, 93), (68, 93), (34, 93), (68, 93), (68, 93), (68, 93), (68, 93), (55, 93), (63, 93), (63, 93), (64, 93), (40, 93), (30, 93), (40, 93), (42, 93), (11, 93), (17, 93), (29, 93), (79, 93), (37, 93), (17, 93), (15, 93), (2, 93), (22, 93), (8, 93), (23, 93), (25, 93), (23, 93), (31, 93), (23, 93), (32, 93), (40, 93), (40, 93), (41, 93), (38, 93), (38, 93), (40, 93), (35, 93), (2, 93), (1146, 93), (1300, 93), (978, 93), (337, 93), (114, 93), (20, 93), (175, 93), (24, 93), (150, 93), (394, 93), (67, 93), (820, 93), (383, 93), (241, 93), (13, 93), (12, 93), (31, 93), (26, 93), (25, 93), (489, 93), (62, 93), (492, 93), (76, 93), (217, 93), (74, 93), (208, 93), (109, 93), (124, 93), (41, 93), (59, 93), (649, 93), (40, 93), (491, 93), (146, 93), (228, 93), (39, 93), (138, 93), (19, 93), (137, 93), (161, 93), (23, 93), (1126, 93), (193, 93), (170, 93), (270, 93), (183, 93), (298, 93), (25, 93), (8, 93), (232, 93), (39, 93), (293, 93), (104, 93), (273, 93), (108, 93), (268, 93)]\n"
     ]
    }
   ],
   "source": [
    "print(len(decoder_output))\n",
    "print(map(lambda e: e.shape, decoder_output[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'\\t': 68,\n",
       " u'\\n': 0,\n",
       " u' ': 1,\n",
       " u'!': 53,\n",
       " u'\"': 41,\n",
       " u'#': 33,\n",
       " u'$': 78,\n",
       " u'%': 84,\n",
       " u'&': 77,\n",
       " u\"'\": 70,\n",
       " u'(': 34,\n",
       " u')': 35,\n",
       " u'*': 45,\n",
       " u'+': 83,\n",
       " u',': 42,\n",
       " u'-': 69,\n",
       " u'.': 38,\n",
       " u'/': 82,\n",
       " u'0': 59,\n",
       " u'1': 36,\n",
       " u'2': 60,\n",
       " u'3': 80,\n",
       " u'4': 79,\n",
       " u'5': 37,\n",
       " u'6': 55,\n",
       " u'7': 50,\n",
       " u'8': 73,\n",
       " u'9': 51,\n",
       " u':': 54,\n",
       " u';': 74,\n",
       " u'<': 85,\n",
       " u'=': 90,\n",
       " u'>': 86,\n",
       " u'?': 75,\n",
       " u'@': 87,\n",
       " u'A': 2,\n",
       " u'B': 3,\n",
       " u'C': 28,\n",
       " u'D': 29,\n",
       " u'E': 4,\n",
       " u'F': 46,\n",
       " u'G': 5,\n",
       " u'H': 6,\n",
       " u'I': 43,\n",
       " u'J': 63,\n",
       " u'K': 64,\n",
       " u'L': 62,\n",
       " u'M': 56,\n",
       " u'N': 61,\n",
       " u'O': 65,\n",
       " u'P': 7,\n",
       " u'Q': 76,\n",
       " u'R': 52,\n",
       " u'S': 8,\n",
       " u'T': 9,\n",
       " u'U': 66,\n",
       " u'V': 47,\n",
       " u'W': 48,\n",
       " u'X': 71,\n",
       " u'Y': 44,\n",
       " u'Z': 81,\n",
       " u'[': 57,\n",
       " u']': 58,\n",
       " u'^': 91,\n",
       " u'_': 88,\n",
       " u'a': 30,\n",
       " u'b': 10,\n",
       " u'c': 11,\n",
       " u'd': 12,\n",
       " u'e': 13,\n",
       " u'f': 14,\n",
       " u'g': 15,\n",
       " u'h': 16,\n",
       " u'i': 31,\n",
       " u'j': 17,\n",
       " u'k': 18,\n",
       " u'l': 19,\n",
       " u'm': 20,\n",
       " u'n': 21,\n",
       " u'o': 22,\n",
       " u'p': 39,\n",
       " u'q': 72,\n",
       " u'r': 23,\n",
       " u's': 24,\n",
       " u't': 25,\n",
       " u'u': 26,\n",
       " u'v': 27,\n",
       " u'w': 40,\n",
       " u'x': 49,\n",
       " u'y': 32,\n",
       " u'z': 67,\n",
       " u'|': 92,\n",
       " u'~': 89}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chartovec_encoder.dictionary.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
